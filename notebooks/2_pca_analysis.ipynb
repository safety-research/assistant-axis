{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis\n",
    "\n",
    "This notebook runs PCA on role activations and compares PC1 with the assistant axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(0, '..')\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "import plotly.graph_objects as go\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm\n",
    "\n",
    "from assistant_axis import (\n",
    "    load_axis,\n",
    "    compute_pca,\n",
    "    plot_variance_explained,\n",
    "    cosine_similarity_per_layer,\n",
    "    MeanScaler\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update these paths\n",
    "ACTIVATIONS_DIR = Path(\"../outputs/gemma-2-27b/activations\")\n",
    "AXIS_PATH = \"../outputs/gemma-2-27b/axis.pt\"\n",
    "TARGET_LAYER = 22  # Update for your model\n",
    "\n",
    "# Load all activations\n",
    "activation_files = sorted(ACTIVATIONS_DIR.glob(\"*.pt\"))\n",
    "print(f\"Found {len(activation_files)} activation files\")\n",
    "\n",
    "# Stack activations at target layer\n",
    "all_activations = []\n",
    "labels = []\n",
    "\n",
    "for act_file in tqdm(activation_files, desc=\"Loading activations\"):\n",
    "    role = act_file.stem\n",
    "    acts = torch.load(act_file, map_location=\"cpu\", weights_only=False)\n",
    "    \n",
    "    for key, act in acts.items():\n",
    "        all_activations.append(act[TARGET_LAYER])  # (hidden_dim,)\n",
    "        labels.append(f\"{role}:{key}\")\n",
    "\n",
    "activations = torch.stack(all_activations)  # (n_samples, hidden_dim)\n",
    "print(f\"Loaded {len(activations)} activations, shape: {activations.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA with mean centering\n",
    "pca_result, variance_explained, n_components, pca, scaler = compute_pca(\n",
    "    activations,\n",
    "    layer=None,  # Already selected layer\n",
    "    scaler=MeanScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variance explained\n",
    "fig = plot_variance_explained(\n",
    "    variance_explained,\n",
    "    title=\"PCA Variance Explained\",\n",
    "    max_components=50\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare PC1 with Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load axis\n",
    "axis = load_axis(AXIS_PATH)\n",
    "print(f\"Axis shape: {axis.shape}\")\n",
    "\n",
    "# Get PC1 at target layer\n",
    "pc1 = torch.tensor(pca.components_[0])  # (hidden_dim,)\n",
    "\n",
    "# Get axis at target layer\n",
    "axis_layer = axis[TARGET_LAYER]  # (hidden_dim,)\n",
    "\n",
    "# Compute cosine similarity\n",
    "pc1_norm = pc1 / pc1.norm()\n",
    "axis_norm = axis_layer / axis_layer.norm()\n",
    "cosine_sim = float(pc1_norm @ axis_norm)\n",
    "\n",
    "print(f\"\\nCosine similarity between PC1 and Axis at layer {TARGET_LAYER}: {cosine_sim:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Across Layers\n",
    "\n",
    "To compare PC1 with the axis across all layers, we'd need to run PCA at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simplified version - for full layer-wise comparison,\n",
    "# you'd need to load activations for all layers and run PCA at each\n",
    "\n",
    "print(\"\\nTop 5 components variance:\")\n",
    "for i in range(5):\n",
    "    print(f\"  PC{i+1}: {variance_explained[i]*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTotal variance in top 5: {sum(variance_explained[:5])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
