{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA Analysis\n",
    "\n",
    "This notebook runs PCA on role activations and compares PC1 with the assistant axis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "import sys\nsys.path.insert(0, '..')\n\nimport torch\nimport numpy as np\nimport plotly.graph_objects as go\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom huggingface_hub import hf_hub_download\n\nfrom assistant_axis import (\n    load_axis,\n    compute_pca,\n    plot_variance_explained,\n    cosine_similarity_per_layer,\n    MeanScaler\n)"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Configuration\nMODEL_NAME = \"gemma-2-27b\"\nREPO_ID = \"lu-christina/assistant-axis-vectors\"\nACTIVATIONS_DIR = Path(\"../outputs/gemma-2-27b/activations\")\nTARGET_LAYER = 22  # Update for your model\n\n# Load all activations\nactivation_files = sorted(ACTIVATIONS_DIR.glob(\"*.pt\"))\nprint(f\"Found {len(activation_files)} activation files\")\n\n# Stack activations at target layer\nall_activations = []\nlabels = []\n\nfor act_file in tqdm(activation_files, desc=\"Loading activations\"):\n    role = act_file.stem\n    acts = torch.load(act_file, map_location=\"cpu\", weights_only=False)\n    \n    for key, act in acts.items():\n        all_activations.append(act[TARGET_LAYER])  # (hidden_dim,)\n        labels.append(f\"{role}:{key}\")\n\nactivations = torch.stack(all_activations)  # (n_samples, hidden_dim)\nprint(f\"Loaded {len(activations)} activations, shape: {activations.shape}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run PCA with mean centering\n",
    "pca_result, variance_explained, n_components, pca, scaler = compute_pca(\n",
    "    activations,\n",
    "    layer=None,  # Already selected layer\n",
    "    scaler=MeanScaler()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot variance explained\n",
    "fig = plot_variance_explained(\n",
    "    variance_explained,\n",
    "    title=\"PCA Variance Explained\",\n",
    "    max_components=50\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare PC1 with Axis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Load axis from HuggingFace\naxis_path = hf_hub_download(repo_id=REPO_ID, filename=f\"{MODEL_NAME}/assistant_axis.pt\", repo_type=\"dataset\")\naxis = load_axis(axis_path)\nprint(f\"Axis shape: {axis.shape}\")\n\n# Get PC1 at target layer\npc1 = torch.tensor(pca.components_[0])  # (hidden_dim,)\n\n# Get axis at target layer\naxis_layer = axis[TARGET_LAYER]  # (hidden_dim,)\n\n# Compute cosine similarity\npc1_norm = pc1 / pc1.norm()\naxis_norm = axis_layer / axis_layer.norm()\ncosine_sim = float(pc1_norm @ axis_norm)\n\nprint(f\"\\nCosine similarity between PC1 and Axis at layer {TARGET_LAYER}: {cosine_sim:.4f}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cosine Similarity Across Layers\n",
    "\n",
    "To compare PC1 with the axis across all layers, we'd need to run PCA at each layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a simplified version - for full layer-wise comparison,\n",
    "# you'd need to load activations for all layers and run PCA at each\n",
    "\n",
    "print(\"\\nTop 5 components variance:\")\n",
    "for i in range(5):\n",
    "    print(f\"  PC{i+1}: {variance_explained[i]*100:.2f}%\")\n",
    "\n",
    "print(f\"\\nTotal variance in top 5: {sum(variance_explained[:5])*100:.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}